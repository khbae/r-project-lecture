---
title: "2. 패키지란? 3. 데이터 처리"
author: "hyo"
date: '2020 3 26'
output: html_document
---
## 2. 패키지란?

* 각 언어에서 제공하는 기본적인 함수로는 원하는 기능을 100% 수행할 수 없음
* 사용자의 목적에 맞게 여러 함수들을 만든 후 꾸러미로 묶은 것이 패키지
* 타 언어 대비 R은 수많은 패키지를 자랑함
* 아래 그림은 R을 관리하는 CRAN에 공식적으로 등록된 패키지 숫자. 이 외에도 github를 통해 공유되는 비공식 패키지도 존재함 (https://github.com/hyunyulhenry/HenryQuant)
* 이 중 사용자들이 가장 많이 다운로드 받은 패키지의 상위권에는 R studio에서 관리하는 패키지들, 그 중에서도 tidyverse 패키지가 대다수를 차지함 (2019년 12월 17~18일 기준)


### 2.1 tidyverse 패키지란?

* R studio에서 만든 패키지 중 핵심 패키지들을 묶은 Package of Packages
* R 언어의 대표적 인물인 Hadley Wickham, R studio의 창업자인 JJ Allaire, 언어와 시각화를 전담하는 Yihui Xie 등의 R Studio 직원이 전담하여 패키지들을 만들고 업데이트 중
* https://www.tidyverse.org/


### 2.2 데이터 과학 프로세스

* Hadley Wickham에 따르면 데이터 과학 업무 과정은 다음과 같다.
* 즉 데이터 불러오기, 데이터 정리, 데이터 탐색, 소통의 4가지 단계로 구분됨
* 각 단계에 맞게 tidyverse와 R studio에서 제공하는 각종 패키지가 존재

## 3. 데이터 처리

* 일반적인 R 사용자와 고수를 가르는 스킬, %>%!!
* magrittr의 파이프 오퍼레이터(%>%)를 통해 직관적으로 코드 표현이 가능해짐
* f(x)의 코드를 x %>% f의 형태로 표현 가능
* f(x, y) 의 경우 x %>% f(y) 혹은 x %>% f(., y)
* 먼저 다음의 예제를 살펴보도록 하자

``` {r}
x = c(0.3078, 0.2577, 0.5523, 0.0564, 0.4685,
      0.4838, 0.8124, 0.3703, 0.5466, 0.1703)

print(x)
``` 

* 다음 값을 계산하고자 함
  + 1. 각 값들의 로그값을 구할 것
  + 2. 로그값들의 계차를 구할 것
  + 3. 구해진 계차의 지수값을 구할 것
  + 4. 소수 둘째 자리까지 반올림할 것
* 위의 계산을 위해서는 다음과 같이 코드를 짜야 함
* 많은 괄호로 인해 코드가 직관적이지 않으며, 실수를 범할 수 있음  
``` {r}
round(exp(diff(log(x))), 2)
```

* 반면 magrittr의 파이프 오퍼레이터(%>%)를 사용할 경우 직관적으로 표현 가능

``` {r}
library(magrittr)
x %>% log() %>% diff() %>% exp() %>% round(., 2)
```

* 만약 magrittr 라이브러리가 설치 되있지않다면 설치!
  + install.packages("magrittr")를 통해 설치 가능
  + 다른 사람에게 코드를 넘겨 주어야하는 상황이라면 아래와 같이 코딩을 하는것을 추천한다
  + require() 함수는 library() 역할과 magrittr라이브러리의 필요 유무를 True/False로 반환
``` {r}
if(!require(magrittr)){install.packages("magrittr");library(magrittr)}
x %>% log() %>% diff() %>% exp() %>% round(., 2)
```

### 3.1 데이터 import
* 데이터 분석에서 가장 중요한 단계는 데이터를 불러오는 것
* 데이터는 csv, excel, sql, hadoop, web 등 다양한 곳에 존재

#### 3.1.1 readr
* csv(comma-separated values)의 경우 readr 패키지의 read_csv()를 통해 불러올 수 있음
* 기본 함수인 read.csv() 대비 속도가 빠르며, 티블 형태로 값이 저장됨

``` {r}
library(readr)
data = read_csv('redwines.csv') #원하는 파일 수정가능
print(data)
```

* 웹에 존재하는 csv 데이터도 read_csv() 함수를 통해 쉽게 불러올 수 있음
* French Library의 3 factor 데이터 다운로드 (https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html)

``` {r,message=FALSE,warning=FALSE}
library(readr)
temp = tempfile()
url = 'https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Research_Data_Factors_CSV.zip'
download.file(url, temp, quiet = TRUE)

ff = read_csv(unz(temp, "F-F_Research_Data_Factors.CSV"), skip = 3)
print(ff)
```

#### 3.1.2 readxl 
* 일반적으로 많이 사용하는 데이터 형태
* read_excel() 이용해 불러오기 가능

read_excel() 이용해 불러오기 가능

``` {r,message=FALSE,warning=FALSE}
library(readxl)

file = 'table1.xlsx'
data_excel = read_excel(file)
print(data_excel)
```


* readxl 패키지의 excel_sheets()를 통해 시트 확인 가능
* 이를 통해 모든 시트의 데이터 불러오기 가능

``` {r}
sheet_list = excel_sheets(file)
print(sheet_list)
```

``` {r}
data_list = lapply(sheet_list, function(x) {
  read_excel(file, sheet = x)
})
names(data_list) = sheet_list

data_list %>% lapply(., head)
```

### 3.2 데이터 다루기
* 문자열을 다루는 stringr, 시계열을 다루는 lubridate, 팩터형을 다루는 forcats 등 다양한 패키지가 존재
* 이들 패키지는 데이터 변형 단계에서 dplyr 패키지와 연동해 사용됨

#### 3.2.1 tibble
* 전통적으로 데이터 분석에는 데이터프레임 형태가 많이 쓰임
* 불필요한 것은 덜어내고 필요한 사항을 집약 → 티블 구조

* 기본 데이터셋인 mtcars의 경우 데이터프레임 형태로 되어있으며, 이를 출력하면 다음과 같음

``` {r}
print(mtcars)
```


* 그러나 이를 티블 형태로 변환하여 출력하면, 훨씬 깔끔한 형태로 출력이 됨
* 행과 열의 갯수를 알 수 있으며, 상위 10개 행만이 출력됨
* 각 컬럼 하부에 데이터 타입이 표시됨

``` {r}
library(tibble)
mtcars %>% as.tibble() %>% print()
```
#### 3.2.2 Tidy

* 데이터 분석 전 테이블을 깔끔하게(tidy) 정리하는 단계 
  + 각 데이터에 대한 클렌징 처리
  + 컬럼을 나누거나 합침
  + 원하는 형태로 행과 열을 변경
  + 결측치 데이터(NA) 처리

* 주로 다음의 패키지가 사용됨 
  + tidyr, dplyr: 전반적인 데이터 처리
  + forcats: 팩터 처리
  + lubridate: time 처리
  + stringr: 문자 처리

* 파마프렌치 3 factor 데이터 사용


``` {r}
head(ff)
```


##### 컬럼 조작하기
* 3 factor 데이터는 다음과 같이 수정해야 함 
  + yyyymm인 데이터와 yyyy인 데이터가 존재하므로, yyyymm인 데이터만 선택
  + Time Index에 해당하는 X1을 Date로 변경
  + Date를 월말 기준으로 변경
  + 각 숫자가 % 단위이므로, 100으로 나누어 숫자로 변환
  + NA 삭제
  
``` {r}
library(dplyr)
library(tidyr)
library(lubridate)
library(xts)
library(stringr)
ff_mod = ff %>% 
  rename('Date' = 'X1') %>% # dplyr
  filter(str_length(Date) == 6) %>% # dplyr
  mutate(Date = sub("(\\d{4})", "\\1-", Date)) %>% # dplyr & regex
  mutate_at(vars(-Date), list(~(. / 100))) %>%  # dplyr
  na.omit()

head(ff_mod)
```

``` {r}
tail(ff_mod)
```

```{r}
##### January Effects ###
##### Jan Returns > Other Month Returns ####

df = ff %>%
  rename("Date"="X1","Mkt_RF" = "Mkt-RF") %>%
  na.omit() %>%
  gather(-Date,key="factor",value="return")

df %>%
  mutate(month = substr(Date,5,7)) %>%
  filter(month !="", factor != "RF") %>%
  group_by(factor,month) %>%
  summarize(month_return = mean(return)) %>%
  pivot_wider(names_from="factor",values_from="month_return") %>%
  select(month,Mkt_RF,SMB,HML)

```

* separate() 함수를 이용하여, Date에서 연도와 월을 각각 분해하여 Year, Month 컬럼을 생성

``` {r}
ff_mod2 = ff_mod %>%
  separate(Date, c('Year', 'Month'), sep = '-')

print(ff_mod2)
```

* unite() 함수를 이용해 반대로 다시 Date 컬럼을 생성

``` {r}
ff_mod2 %>%
  unite('Date', c('Year', 'Month'), sep = '-') %>% head()
```


##### 데이터 형태 변경
* 데이터는 크게 wide(가로로 긴 형태)와 long(세로로 긴 형태)로 나눌 수 있음
* ggplot에서 그룹 별 그래프를 그리기 위해서는 long 형태로 변형해야 하며, 년/월별 데이터를 보고자 할때는 wide 형태로 변형해야 함
* pivot_longer() 함수는 long 형태, pivot_wider() 함수는 wide 형태로 변형함
* 예제를 위해 2018년~2019년 데이터만 선택


``` {r}
ff_select = ff_mod %>%
  filter(str_sub(Date, 1, 4) %in% c(2018, 2019))

print(ff_select)
```

* 해당 데이터를 long(세로로 긴 형태)로 변경
* 기존 gather() 함수가 pivot_longer()로 이름이 변경됨
* 인자는 다음과 같음 
  + cols: long 형태로 변형할 컬럼 선택, 마이너스(-)를 입력할 경우 해당 컬럼을 그대로 보존
  + names_to: 컬럼 이름들이 long 형태로 변형될 때, 해당 컬럼의 이름
  + values_to: 각 value들이 long 형태로 변형될 때, 해당 컬럼의 이름
* ggplot을 이용한 시각화에 필수적으로 사용

``` {r}
ff_select %>%
  gather(key = 'Factor', value = 'Return', -Date)

ff_select %>%
  pivot_longer(cols = -Date, names_to = 'factor', values_to = 'return')

```


* 변경 전(wide)과 변경 후(long)을 비교하면 다음과 같다.
![](C:/Users/haley/Desktop/haley/task/R/Rbasic/statistic_lecture/table1.png) 

* 위데이터를 다시 변경하고 싶을 때는 다음과 같이 쓰면된다
  + pivot_wider(names_from = 'factor',values_from = 'return')
```{r}

f_long = ff_select %>%
  pivot_longer(cols = -Date, names_to = 'factor', values_to = 'return')
f_long
f_long %>% pivot_wider(names_from = 'factor',
              values_from = 'return')
```



* 이번에는 2018년과 2019년 데이터를 년도와 월별로 wide 형태로 변경
* 기존 spread() 함수가 pivot_wider()로 이름이 변경됨
* 인자는 다음과 같음 
  + id_cols: 보존하고자 하는 컬럼
  + names_from: 열 이름으로 들어갈 컬럼
  + values_from: 각 셀의 데이터로 들어갈 컬럼
  
``` {r}
ff_select %>%
  pivot_longer(cols = -Date, names_to = 'factor',
               values_to = 'return') %>%
  separate(Date, c('Year', 'Month'), sep = '-') %>%
  pivot_wider(id_cols = c(Year, factor),
              names_from = 'Month',
              values_from = 'return')
```

              
* 변경 전(long)과 변경 후(wide)을 비교하면 다음과 같다.
![](C:/Users/haley/Desktop/haley/task/R/Rbasic/statistic_lecture/table2.png) 


##### 데이터 합치기
* *_join() 함수를 이용해 두 테이블을 하나로 합칠 수 있음
![](C:/Users/haley/Desktop/haley/task/R/Rbasic/statistic_lecture/table3.png) 

``` {r}
test1 <- data.frame(name=c('서현','민아','유진','다미'), math = c(75, 85,90,70),stringsAsFactors=FALSE)
test2 <- data.frame(name = c('규리','서현','민아','유진','민경'),english = c(80,90,95,70,85),stringsAsFactors=FALSE)
test1
test2
```

* inner join
  + inner join은 키(key)를 기준으로 두 테이블에 같이 존재하는 데이터를 추출합니다. 여기에서는 이름(key)을 기준으로 보면 두 테이블에 서현,민아, 유진이가 있네요. ’name’을 기준으로 join하기 위해 by 인자에는 ’name’을 쓰도록 합니다. inner join은 집합에서 교집합의 개념과 동일합니다. dplyr패키지에서 inner_join 함수를 사용합니다.
``` {r}
inner_join(test1,test2,by='name')
```

* full (outer) join
  + full join은 키(key)를 기준으로 두 테이블에 존재하는 모든 데이터를 뽑아내어 병합합니다. 여기에서는 이름(key)을 기준으로 보면 두 테이블에 서현, 민아, 유진, 다미, 규리 민경이가 있네요.
수학 테이블에는 규리와, 민경이의 데이터가 존재하지 않습니다. 반면 영어 테이블에는 다미의 데이터가 존재하지 않습니다. inner join 과 다르게 full join 은 각 테이블 모든 데이터를 병합합니다.집합에서는 합집합의 개념과 동일합니다. 각 테이블에 없는 학생은 결측값(NA)로 반환됩니다. dplyr패키지에서 full_join 함수를 사용합니다.
``` {r}
full_join(test1,test2,by='name')
```

* left join
  + left join은 왼쪽에 있는 테이블의 key을 기준으로 병합합니다. 왼쪽 테이블을 수학점수 테이블로 놓고, 오른쪽 테이블을 영어점수 테이블로 세팅해보겠습니다. 수학점수 테이블에는 서현, 민아, 유진, 다미가 있습니다. 이때 오른쪽 테이블(영어점수 테이블)과 병합합니다. dplyr패키지에서 left_join 함수를 사용합니다.
``` {r}
left_join(test1,test2,by='name')
```

* right join
  + left join과 반대로 right join 은 영어점수 테이블(오른쪽 테이블)에 있는 데이터를 반환합니다. 규리와 민경이는 수학점수 테이블에 존재하지 않으므로 결측값(NA)를 반환했습니다. dplyr패키지에서 right_join 함수를 사용합니다.
``` {r}
right_join(test1,test2,by='name')
```

* quantmod 패키지를 이용해 Yahoo API를 통해 애플 주식의 주가(AAPL)를 다운로드
* 월말에 해당하는 주가만 뽑아, 월간 수익률을 계산

``` {r}
library(quantmod)
library(PerformanceAnalytics)

price = getSymbols('AAPL', from = '1900-01-01', auto.assign = FALSE) %>% Ad()

head(price)
```

``` {r}
tail(price)
```


``` {r}
library(ggplot2)
ep = endpoints(price)

ret_mod = price[ep] %>% Return.calculate %>%
  set_colnames('AAPL') %>%
  fortify() %>%
  mutate(Index = str_sub(Index, 1, 7),
         AAPL = round(AAPL, 4)) 

head(ret_mod)
```

* 3 Factor 테이블(ff_mod)의 Date와 애플 수익률(ret_mod)의 Index가 매칭되므로, 이를 이용해 테이블을 합쳐줌

``` {r}
df = left_join(ff_mod, ret_mod,
                         by = c('Date' = 'Index')) %>% na.omit()
                                
print(df)
```

### 3.3 탐색적 데이터 분석
* Exploratory Data Analysis
* 데이터가 어떠한 특성을 가지고 있는지에 대한 분석 및 시각화 과정
* 데이터 분석에는 dplyr, 시각화에는 ggplot2 패키지가 사용됨

#### 3.3.1 rvest/dplyr를 활용
* 다음 함수가 대표적으로 사용됨 
  + select(): 원하는 컬럼 선택
  + filter(): 조건에 맞는 행 선택
  + mutate(): 열 생성 및 데이터 변형
  + group_by(): 그룹별로 데이터를 묶기
* 이 외에도 rvest/dplyr 패키지에는 데이터 분석을 위한 대부분의 함수가 포함되어 있음

##### Titanic 예제로 데이터 처리
``` {r}
library(rvest)
library(dplyr)
Titanic = read.csv('Titanic.csv',stringsAsFactors = F)
Titanic %>% head()
``` 

##### `match()`를 활용하여 데이터의 변수 위치 확인
``` {r}
names(Titanic)
#names에서 "pclass","survived","ticket"의 위치
match(c("pclass","survived","ticket"),  names(Titanic))
``` 
* 데이터를 추출하는 방법으로는 여러가지가 있다
  + 아래 코드 모두 동일한 결과를 갖는다
``` {r}
Titanic[, match(c("pclass","survived","ticket"),  names(Titanic)) ] %>% head()
Titanic[,c("pclass","survived","ticket") ] %>% head()
Titanic[c("pclass","survived","ticket")] %>% head()
```

##### 원하는 데이터 추출하기
* Titanic 데이터에서 생존한 사람 survived 변수가 1을 가진 사람만 데이터 추출해보자
  + 위치를 확인하여 대괄호[] 안에 넣어 인덱싱을 한다
  + survived 변수가 1을 가진 행 추출
``` {r}
(Titanic$survived == 1) %>% head() #T/F 형태로 나옴
Titanic[Titanic$survived == 1, ] %>% head()
#-> 같은 결과 head(Titanic[Titanic$survived == 1, ])
```

##### `which()` 함수를 활용하여 데이터 추출하기
``` {r}
Titanic[Titanic$age<20, c("age","survived","ticket")] %>% head() #NA 포함
Titanic[which(Titanic$age<20), c("age","survived","ticket")] %>% head() #NA 제외
which(Titanic$age<20)
```

##### `unique() table()` 변수의 값들 집계하기
* unique()함수는 데이터의 값이 어떤것들이 있는지 확인
* table()함수는 데이터의 값들의 각각의 갯수 확인
  + NA는 집계되지않는다
``` {r}
Titanic$survived %>% unique()
t = table(Titanic$survived)
t
```

##### `is.na()` NA값 처리
* NA값에 사칙연산을 해도 NA가된다
* is.na()함수를 통해 NA값을 True/False로 반환
  + !is.na()를 하면 NA가 아닌 값들만 추출할 수 있다
``` {r}
Titanic_ex <- Titanic
# 달러 -> 원화
Titanic_ex$fare <- Titanic_ex$fare * 1227
#NA * 1227 = NA 
is.na(Titanic_ex$fare) %>% head() #True/False로 나옴
nrow(Titanic_ex)
Titanic_ex <- Titanic_ex[!is.na(Titanic_ex$fare),] 
nrow(Titanic_ex) #2명 삭제됨
```

##### `mean() by() aggregate()`함수 사용 평균 구하기
* sex별 age 평균구하기 
  + 1. mean을 사용하여 각각의 데이터 선택 후 평균구하는 방법
  + 2. by를 사용하여 그룹을 나누어 평균을 구하는 방법
  + 3. aggregate를 사용하여 그룹을 나누어 평균을 구하는 방법(sex = ""일경우는 나오지않는다)
* na.rm = T 을 사용하여 결측값을 제거
* 이상값을 제거 후 mean값을 구하고 싶을때 trim옵션을 사용한다
``` {r}
Titanic$sex %>% unique()
mean( Titanic$age[Titanic$sex == "female"], na.rm = T )
mean( Titanic$age[Titanic$sex == "male"], na.rm = T )
mean( Titanic$age[Titanic$sex == ""], na.rm = T )

by( data = Titanic$age, INDICES =  Titanic$sex, 
    FUN  = mean, na.rm = TRUE)

aggregate(formula = age ~ sex, data = Titanic,
          FUN = mean, na.rm = TRUE)
aggregate(formula = age ~ sex, 
               data = Titanic, FUN = mean, na.rm = TRUE,trim = 0.05) #trim 양옆 각각 5%씩 빼고
```

##### `filter() select() summarize()`함수 사용법
* filter()를 통해 원하는 데이터를 추출할 수 있음
* select()을 통해 원하는 변수만을 선택
* summarize()를통해 mean,max,min등의 값을 구할 수 있음 
``` {r}
Titanic %>%  
  filter(Titanic$sex=="male") %>%  
  select(age,sex) %>%  
  summarize(mean_age = mean(age, na.rm = TRUE))
```

##### `table()`함수 사용법
* 변수 하나만을 적용하면 하나의 집계표가 나오지만 두개의 변수를 적용하면 교차테이블을 만들 수 있다
``` {r}
Titanic %>% head()
table(Titanic$sex)
table(Titanic$sex, Titanic$survived) #교차 테이블 작성
```

##### 데이터 정렬하기
* order(),arrange() : 순서대로 정렬 default = 오름차순
``` {r}
Titanic[order(Titanic$name),] %>% head(10)#name 정렬

tmp <- Titanic 
tmp <- tmp[order(tmp$age, decreasing = TRUE),]
tmp <- tmp[order(tmp$name),]

#정렬 오름차순
Titanic %>% arrange(name, age) %>% head()

#정렬 내림차순
Titanic %>% arrange(desc(name), age) %>% head()
```


##### `mutate()` 파생변수 생성
``` {r}
Titanic_ex <- Titanic %>% 
  filter(!is.na(Titanic$fare)) %>%
  mutate(won = fare * 1227) 
head(Titanic_ex)
```

##### `group_by()` 그룹핑
* group_by()을 통해 그룹핑을 한다
* tally()는 table()역할과 같다
  + table()이 결과가 더 깔끔하게 나옴
``` {r}
Titanic %>%
  group_by(sex) %>%
  summarize(mean_age = mean(age, na.rm = TRUE))

Titanic %>%
  filter(!is.na(age)) %>%
  group_by(sex, survived) %>%
  summarize(mean_age = mean(age),
            var_age = var(age),
            min_age = min(age),
            max_age = max(age)) %>%
  print(n = 5)

# -----------------------------------
#table(Titanic$sex)
Titanic %>%
  group_by(sex) %>%
  tally()

#table(Titanic$survived,Titanic$sex)
Titanic %>%
  group_by(survived, sex) %>%
  tally()

```

##### `melt() dcast()`함수 사용하여 데이터 형태 바꾸기
* melt() :열 이름을 variable로 해당 열의 행값들을value값으로 바꾸어준다
* dcast(): melt와 반대의 역할 
``` {r}
library(reshape2)
airquality %>% head(3)
data = melt(airquality, id.vars= c("Month","Day"))
data %>% head()

dcast(data, Month + Day ~ variable, 
      value.var ="value") %>% head()
```




















